import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as n,o as i,c as r,a as s,b as e,e as o,f as a}from"./app-50cbe7c2.js";const c="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Fig1.png",m="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Fig2.png",p="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Table1.png",h="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Table2.png",d="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Fig3.png",u="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Fig5.png",g="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Table3.png",y="/images/DETRs-Beat-YOLOs-on-Real-time-Object-Detection/Fig6.png",f={},b={href:"http://arxiv.org/abs/2304.08069",target:"_blank",rel:"noopener noreferrer"},v=a('<h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h2><p>Recently, end-to-end transformer-based detectors (DETRs) have achieved remarkable performance. <mark>However, the high computational cost of DETRs limits their practical application and prevents them from fully exploiting the advantage of no post-processing, such as non-maximum suppression (NMS).</mark> In this paper, we first analyze the negative impact of NMS on the accuracy and speed of existing real-time object detectors, and establish an end-to-end speed benchmark. To solve the above problems, we propose a <mark>Real-Time DEtection TRansformer (RT-DETR)</mark>, the first real-time end-to-end object detector to our best knowledge. Specifically, we design an efficient hybrid encoder to efficiently process multi-scale features by decoupling the intra-scale interaction and cross-scale fusion, and propose IoU-aware query selection to further improve performance by providing higher quality initial object queries to the decoder. In addition, our proposed detector supports flexible adjustment of the inference speed by using different decoder layers without the need for retraining, which facilitates the practical application in various real-time scenarios. <mark>Our RT-DETR-L achieves 53.0% AP on COCO val2017 and 114 FPS on T4 GPU, while RT-DETR-X achieves 54.8% AP and 74 FPS, outperforming the stateof-the-art YOLO detectors of the same scale in both speed and accuracy. Furthermore, our RT-DETR-R50 achieves 53.1% AP and 108 FPS, outperforming DINO-DeformableDETR-R50 by 2.2% AP in accuracy and by about 21 times in FPS.</mark></p><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><p>There are two typical architectures for modern object detectors:</p><ul><li>CNN-based</li><li>Transformer-based</li></ul><figure><img src="'+c+'" alt="Fig1" tabindex="0" loading="lazy"><figcaption>Fig1</figcaption></figure><h3 id="cnn-based" tabindex="-1"><a class="header-anchor" href="#cnn-based" aria-hidden="true">#</a> CNN-based</h3><p>Two detection paradigms(emerged already):</p><ul><li>anchor-based</li><li>anchor-free</li></ul><p>These real-time detectors usually require NMS for post-processing, which is usually difficult to optimize and not robust enough, resulting in delays in the inference speed of the detectors.</p><h3 id="transformer-based" tabindex="-1"><a class="header-anchor" href="#transformer-based" aria-hidden="true">#</a> Transformer-based</h3><p>The Transformer-based object detectors (DETRs) have received extensive attention from the academia since it was proposed due to its elimination of various hand-crafted components, such as non-maximum suppression (NMS). This architecture greatly simplifies the pipeline of object detection and realizes end-to-end object detection.<br> The issue of the high computational cost of DETRs has not been effectively addressed, which limits the practical application of DETRs and results in an inability to take full advantage of their benefits.</p><h3 id="proposed-encoder" tabindex="-1"><a class="header-anchor" href="#proposed-encoder" aria-hidden="true">#</a> Proposed encoder</h3><p>To achieve real-time object detection, we design an efficient hybrid encoder to replace the original transformer encoder. By decoupling the intra-scale interaction and cross-scale fusion of multi-scale features, the encoder can efficiently process features with different scales.</p><h3 id="iou-aware-query-selection" tabindex="-1"><a class="header-anchor" href="#iou-aware-query-selection" aria-hidden="true">#</a> IoU-aware query selection</h3><p>To further improve the performance, we propose IoU-aware query selection, which provides higher quality initial object queries to the decoder by providing IoU constraints during training.<br> In addition, our proposed detector supports flexible adjustment of the inference speed by using different decoder layers without the need for retraining, which benefits from the design of the decoder in the DETR architecture and facilitates the practical application of the real-time detector.</p><h3 id="contribution" tabindex="-1"><a class="header-anchor" href="#contribution" aria-hidden="true">#</a> Contribution</h3><ol><li>we propose the first real-time end-to-end object detector that not only outperforms current state-of-the-art real-time detectors in both speed and accuracy, but also requires no post-processing, so its inference speed is not delayed and remains stable;</li><li>we analyze the impact of NMS on real-time detectors in detail and draw conclusions about current real-time detectors from a post-processing perspective;</li><li>our work provides a feasible solution for the real-time implementation of current end-to-end detectors, and the proposed detector can flexibly adjust the inference speed by using different decoder layers without the need for retraining, which is difficult in existing real-time detectors.</li></ol><h2 id="related-work" tabindex="-1"><a class="header-anchor" href="#related-work" aria-hidden="true">#</a> Related work</h2><h3 id="real-time-object-detectors" tabindex="-1"><a class="header-anchor" href="#real-time-object-detectors" aria-hidden="true">#</a> Real-time Object Detectors</h3><p>The aforementioned detectors(anchor-based and anchor-free detectors) produce numerous redundant bounding boxes, requiring the utilization of NMS during the post-processing stage to filter them out. Unfortunately, this leads to performance bottlenecks, and the hyperparameters of NMS have a significant impact on the accuracy and speed of the detectors.</p><h3 id="end-to-end-object-detectors" tabindex="-1"><a class="header-anchor" href="#end-to-end-object-detectors" aria-hidden="true">#</a> End-to-end Object Detectors</h3><p>DETR eliminates the hand-designed anchor and NMS components in the traditional detection pipeline. Instead, it employs the bipartite matching and directly predicts the one-to-one object set. By adopting this strategy, DETR simplifies the detection pipeline and mitigates the performance bottleneck caused by NMS.<br> DETR suffers from two major issues:</p><ul><li>slow training convergence.</li><li>hard-to-optimize queries.</li></ul><h3 id="multi-scale-features-for-object-detection" tabindex="-1"><a class="header-anchor" href="#multi-scale-features-for-object-detection" aria-hidden="true">#</a> Multi-scale Features for Object Detection</h3><p>FPN introduces a feature pyramid network that fuses features from adjacent scales. Subsequent works extend and enhance this structure, and they are widely adopted in real-time object detectors. Zhu first introduce multi-scale features into DETR and improve the performance and convergence speed, but this also leads to a significant increase in the computational cost of DETR. Although the deformable attention mechanism alleviates computational cost to some degree, the incorporation of multiscale features still results in a high computational burden.</p><h2 id="end-to-end-speed-of-detectors" tabindex="-1"><a class="header-anchor" href="#end-to-end-speed-of-detectors" aria-hidden="true">#</a> End-to-end Speed of Detectors</h2><h3 id="analysis-of-nms" tabindex="-1"><a class="header-anchor" href="#analysis-of-nms" aria-hidden="true">#</a> Analysis of NMS</h3><p>Two hyperparameters are required in NMS:</p><ul><li>score threshold.</li><li>IoU threshold.</li></ul><p>To verify this opinion, we leverage YOLOv5 (anchorbased) [13] and YOLOv8 (anchor-free) [14] for experiments. We first count the number of prediction boxes remaining after the output boxes is filtered by different score thresholds with the same input image. We sample some scores from 0.001 to 0.25 as thresholds to count the remaining prediction boxes of two detectors and draw them into a histogram, which intuitively reflects that NMS is susceptible to its hyperparameters, as shown in Fig. 2.<br> We take YOLOv8 as an example to evaluate the model accuracy on the COCO val2017 and the execution time of the NMS operation under different NMS hyperparameters. The hyperparameters we used and the corresponding results are shown in Tab. 1.</p><figure><img src="'+m+'" alt="Fig2" tabindex="0" loading="lazy"><figcaption>Fig2</figcaption></figure><figure><img src="'+p+'" alt="Table1" tabindex="0" loading="lazy"><figcaption>Table1</figcaption></figure><h3 id="end-to-end-speed-benchmark" tabindex="-1"><a class="header-anchor" href="#end-to-end-speed-benchmark" aria-hidden="true">#</a> End-to-end Speed Benchmark</h3><p>According to the results, we conclude that <mark>for real-time detectors that require NMS post-processing, anchor-free detectors outperform anchor-based detectors with equivalent accuracy because the former takes significantly less post-processing time than the latter</mark>, which was neglected in previous works. The reason for this phenomenon is that anchor-based detectors produce more predicted boxes than anchor-free detectors (three times more in our tested detectors).</p><figure><img src="'+h+'" alt="Table2" tabindex="0" loading="lazy"><figcaption>Table2</figcaption></figure><h2 id="the-real-time-detr" tabindex="-1"><a class="header-anchor" href="#the-real-time-detr" aria-hidden="true">#</a> The Real-time DETR</h2><h3 id="model-overview" tabindex="-1"><a class="header-anchor" href="#model-overview" aria-hidden="true">#</a> Model Overview</h3><p>The proposed RT-DETR consists of a backbone, a hybrid encoder and a transformer decoder with auxiliary prediction heads. The overview of the model architecture is illustrated in Fig. 3. Specifically, we leverage the output features of the last three stages of the backbone {S3,S4,S5} as the input to the encoder. The hybrid encoder transforms multi-scale features into a sequence of image features through intra-scale interaction and cross-scale fusion. Subsequently, the IoU-aware query selection is employed to select a fixed number of image features from the encoder output sequence to serve as initial object queries for the decoder. Finally, the decoder with auxiliary prediction heads iteratively optimizes object queries to generate boxes and confidence scores.</p><figure><img src="'+d+'" alt="Fig3" tabindex="0" loading="lazy"><figcaption>Fig3</figcaption></figure><h3 id="efficient-hybrid-encoder" tabindex="-1"><a class="header-anchor" href="#efficient-hybrid-encoder" aria-hidden="true">#</a> Efficient Hybrid Encoder</h3><h4 id="computational-bottleneck-analysis" tabindex="-1"><a class="header-anchor" href="#computational-bottleneck-analysis" aria-hidden="true">#</a> Computational bottleneck analysis</h4><p>The set of variants gradually improves model accuracy while significantly reducing computational cost by decoupling multi-scale feature interaction into two-step operations of intra-scale interaction and cross-scale fusion<br> We first remove the multiscale transformer encoder in DINO-R50 [46] as baseline A. Next, different forms of encoder are inserted to produce a series of variants based on baseline A, elaborated as follows:</p><ul><li>A -&gt; B: Variant B inserts a single-scale transformer encoder, which uses one layer of transformer block. The features of each scale share the encoder for intrascale feature interaction and then concatenate the output multi-scale features.</li><li>B -&gt; C: Variant C introduces cross-scale feature fusion based on B and feeds the concatenate multi-scale features into the encoder to perform feature interaction.</li><li>C -&gt; D: Variant D decouples the intra-scale interaction and cross-scale fusion of multi-scale features. First, the single-scale transformer encoder is employed to perform intra-scale interaction, then a PANet-like structure is utilized to perform cross-scale fusion.</li><li>D -&gt; E: Variant E further optimizes the intra-scale interaction and cross-scale fusion of multi-scale features based on D, adopting an efficient hybrid encoder designed by us.</li></ul><figure><img src="'+u+'" alt="Fig5" tabindex="0" loading="lazy"><figcaption>Fig5</figcaption></figure><figure><img src="'+g+'" alt="Table3" tabindex="0" loading="lazy"><figcaption>Table3</figcaption></figure><h4 id="hybrid-design" tabindex="-1"><a class="header-anchor" href="#hybrid-design" aria-hidden="true">#</a> Hybrid design</h4>',47),w=s("p",null,[e("The proposed encoder consists of two modules, the "),s("mark",null,"Attention-based Intrascale Feature Interaction (AIFI)"),e(" module and the "),s("mark",null,"CNN-based Cross-scale Feature-fusion Module (CCFM)"),e(". AIFI further reduces computational redundancy based on variant D, which only performs intra-scale interaction on "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mn",null,"5")])]),s("annotation",{encoding:"application/x-tex"},"{S_5}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"5")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])]),e("."),s("br"),e(" CCFM is also optimized based on variant D, inserting several fusion blocks composed of convolutional layers into the fusion path. The role of the fusion block is to fuse the adjacent features into a new feature. The fusion block contains N RepBlocks, and the two-path outputs are fused by element-wise add. We can formulate this process as follows:")],-1),x=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.16em",columnspacing:"1em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mi",{mathvariant:"bold"},"Q"),s("mo",null,"="),s("mi",{mathvariant:"bold"},"K"),s("mo",null,"="),s("mi",{mathvariant:"bold"},"V"),s("mo",null,"="),s("mi",null,"F"),s("mi",null,"l"),s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"S"),s("mn",null,"5")]),s("mo",{stretchy:"false"},")")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("msub",null,[s("mi",null,"F"),s("mn",null,"5")]),s("mo",null,"="),s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"s"),s("mi",null,"h"),s("mi",null,"a"),s("mi",null,"p"),s("mi",null,"e"),s("mo",{stretchy:"false"},"("),s("mi",null,"A"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("mi",{mathvariant:"bold"},"Q"),s("mo",{separator:"true"},","),s("mi",{mathvariant:"bold"},"K"),s("mo",{separator:"true"},","),s("mi",{mathvariant:"bold"},"V"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mi",null,"O"),s("mi",null,"u"),s("mi",null,"t"),s("mi",null,"p"),s("mi",null,"u"),s("mi",null,"t"),s("mo",null,"="),s("mi",null,"C"),s("mi",null,"C"),s("mi",null,"F"),s("mi",null,"M"),s("mo",{stretchy:"false"},"("),s("mo",{stretchy:"false"},"{"),s("msub",null,[s("mi",null,"S"),s("mn",null,"3")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"S"),s("mn",null,"4")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"S"),s("mn",null,"5")]),s("mo",{stretchy:"false"},"}"),s("mo",{stretchy:"false"},")")])])])])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"}," \\begin{equation} \\begin{aligned} &\\bold{Q} = \\bold{K} = \\bold{V} = Flatten(S_5) \\\\ &F_5 = Reshape(Attn(\\bold{Q}, \\bold{K}, \\bold{V})) \\\\ &Output = CCFM(\\{S_3, S_4, S_5\\}) \\end{aligned} \\end{equation} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"4.5em","vertical-align":"-2em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5em"}},[s("span",{style:{top:"-4.5em"}},[s("span",{class:"pstrut",style:{height:"4.5em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5em"}},[s("span",{style:{top:"-4.5em"}},[s("span",{class:"pstrut",style:{height:"2.84em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"2.84em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-1.5em"}},[s("span",{class:"pstrut",style:{height:"2.84em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5em"}},[s("span",{style:{top:"-4.66em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mord mathbf"},"Q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathbf"},"K"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"V"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"Fl"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"tt"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"5")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.16em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"F"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"5")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"es"),s("span",{class:"mord mathnormal"},"ha"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal"},"tt"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathbf"},"Q"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathbf"},"K"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"V"),s("span",{class:"mclose"},"))")])]),s("span",{style:{top:"-1.66em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal"},"tp"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"CCFM"),s("span",{class:"mopen"},"({"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"3")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"4")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"5")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},"})")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5em"}},[s("span",{style:{top:"-4.5em"}},[s("span",{class:"pstrut",style:{height:"4.5em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2em"}},[s("span")])])])])])])])],-1),k=s("p",null,[e("where "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"A"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"n")]),s("annotation",{encoding:"application/x-tex"},"Attn")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal"},"tt"),s("span",{class:"mord mathnormal"},"n")])])]),e(" represents the multi-head self-attention, and "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"s"),s("mi",null,"h"),s("mi",null,"a"),s("mi",null,"p"),s("mi",null,"e")]),s("annotation",{encoding:"application/x-tex"},"Reshape")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"es"),s("span",{class:"mord mathnormal"},"ha"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mord mathnormal"},"e")])])]),e(" represents restoring the shape of the feature to the same as "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mn",null,"5")])]),s("annotation",{encoding:"application/x-tex"},"S_5")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"5")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),e(", which is the inverse operation of "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"F"),s("mi",null,"l"),s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n")]),s("annotation",{encoding:"application/x-tex"},"Flatten")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"Fl"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"tt"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"n")])])]),e(".")],-1),T=s("h3",{id:"iou-aware-query-selection-1",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#iou-aware-query-selection-1","aria-hidden":"true"},"#"),e(" IoU-aware Query Selection")],-1),R=s("p",null,[e("The object queries in DETR are a set of learnable embeddings, which are optimized by the decoder and mapped to classification scores and bounding boxes by the prediction head. However, these object queries are difficult to interpret and optimize because they have no explicit physical meaning."),s("br"),e(" We propose IoU-aware query selection by constraining the model to produce high classification scores for features with high IoU scores and low classification scores for features with low IoU scores during training. Therefore, the prediction boxes corresponding to the top K encoder features selected by the model according to the classification score have both high classification scores and high IoU scores. We reformulate the optimization objective of the detector as follows:")],-1),M=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.16em",columnspacing:"1em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("msub",null,[s("mi",null,"L"),s("mtext",null,"box")]),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"b"),s("mo",null,"^")]),s("mo",{separator:"true"},","),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("msub",null,[s("mi",null,"L"),s("mtext",null,"cls")]),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"c"),s("mo",null,"^")]),s("mo",{separator:"true"},","),s("mstyle",{mathcolor:"red"},[s("mover",{accent:"true"},[s("mi",null,"b"),s("mo",null,"^")])]),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mstyle",{mathcolor:"red"},[s("mi",null,"b")]),s("mo",{stretchy:"false"},")")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("msub",null,[s("mi",null,"L"),s("mtext",null,"box")]),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"b"),s("mo",null,"^")]),s("mo",{separator:"true"},","),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("msub",null,[s("mi",null,"L"),s("mtext",null,"cls")]),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"c"),s("mo",null,"^")]),s("mo",{separator:"true"},","),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mstyle",{mathcolor:"red"},[s("mi",null,"I"),s("mi",null,"o"),s("mi",null,"U")]),s("mo",{stretchy:"false"},")")])])])])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"}," \\begin{equation} \\begin{aligned} L(\\hat{y}, y) &= L_\\text{box}(\\hat{b}, b) + L_\\text{cls}(\\hat{c}, \\textcolor{red}{\\hat{b}}, y, \\textcolor{red}{b}) \\\\ &= L_\\text{box}(\\hat{b}, b) + L_\\text{cls}(\\hat{c}, c, \\textcolor{red}{IoU}) \\end{aligned} \\end{equation} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.2358em","vertical-align":"-1.3679em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8679em"}},[s("span",{style:{top:"-3.8679em"}},[s("span",{class:"pstrut",style:{height:"3.8679em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8679em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-2.2921em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3679em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8679em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"box")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9579em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"b")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.25em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"cls")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"c")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent",style:{color:"red"}},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9579em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{color:"red"}},"b")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.25em"}},[s("span",{class:"mord",style:{color:"red"}},"^")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{color:"red"}},"b"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-2.2921em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"box")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9579em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"b")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.25em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"cls")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"c")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em",color:"red"}},"I"),s("span",{class:"mord mathnormal",style:{color:"red"}},"o"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em",color:"red"}},"U"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3679em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3679em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8679em"}},[s("span",{style:{top:"-3.8679em"}},[s("span",{class:"pstrut",style:{height:"3.8679em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3679em"}},[s("span")])])])])])])])],-1),_=s("p",null,[e("where "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")])]),s("annotation",{encoding:"application/x-tex"},"\\hat{y}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])])])])]),e(" and "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y")]),s("annotation",{encoding:"application/x-tex"},"y")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")])])]),e(" denote prediction and ground truth, "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",null,"="),s("mo",{stretchy:"false"},"{"),s("mover",{accent:"true"},[s("mi",null,"c"),s("mo",null,"^")]),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"b"),s("mo",null,"^")]),s("mo",{stretchy:"false"},"}")]),s("annotation",{encoding:"application/x-tex"},"\\hat{y} = \\{\\hat{c}, \\hat{b}\\}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2079em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"{"),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"c")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9579em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"b")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.25em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"mclose"},"}")])])]),e(" and "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mo",{stretchy:"false"},"{"),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mi",null,"b"),s("mo",{stretchy:"false"},"}")]),s("annotation",{encoding:"application/x-tex"},"y = \\{c, b\\}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"{"),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},"}")])])]),e(", "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"c")]),s("annotation",{encoding:"application/x-tex"},"c")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"c")])])]),e(" and "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])]),e(" represent categories and bounding boxes, respectively. We introduce the IoU score into objective function of the classification branch to realize the consistency constraint on the classification and localization of positive samples.")],-1),D=a('<h4 id="effectiveness-analysis" tabindex="-1"><a class="header-anchor" href="#effectiveness-analysis" aria-hidden="true">#</a> Effectiveness analysis</h4><p>According to the visualization results, we found that the most striking feature is that a large number of blue points are concentrated in the top right of the figure, while red points are concentrated in the bottom right. This shows that the model trained with IoU-aware query selection can produce more high-quality encoder features.<br> Furthermore, we quantitatively analyze the distribution characteristics of the two types of points. There are 138% more blue points than red points in the figure, i.e. more red points with a classification score less than or equal to 0.5, which can be considered as low-quality features. We then analyze the IoU scores of features with classification scores greater than 0.5, and we find that there are 120% more blue points than red points with IoU scores greater than 0.5. Quantitative results further demonstrate that the IoU-aware query selection can provide more encoder features with accurate classification (high classification scores) and precise location (high IoU scores) for object queries, thereby improving the accuracy of the detector. The detailed quantitative results are presented in Sec. 5.4.</p><figure><img src="'+y+'" alt="Fig6" tabindex="0" loading="lazy"><figcaption>Fig6</figcaption></figure><h4 id="scaled-rt-detr" tabindex="-1"><a class="header-anchor" href="#scaled-rt-detr" aria-hidden="true">#</a> Scaled RT-DETR</h4>',4),z=s("p",null,[e("To provide a scalable version of RT-DETR, "),s("mark",null,"we replace the ResNet backbone with HGNetv2"),e(". We scale the backbone and hybrid encoder together using a depth multiplier and a width multiplier. Thus, we get two versions of RT-DETR with different numbers of parameters and FPS. For our hybrid encoder, we control the depth multiplier and width multiplier by adjusting the number of "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"p"),s("mi",null,"B"),s("mi",null,"l"),s("mi",null,"o"),s("mi",null,"c"),s("mi",null,"k"),s("mi",null,"s")]),s("annotation",{encoding:"application/x-tex"},"RepBlocks")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"pBl"),s("span",{class:"mord mathnormal"},"oc"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mord mathnormal"},"s")])])]),e(" in CCFM and the embedding dimension of the encoder, respectively. It is worth noting that our proposed RT-DETR of different scales maintains a homogeneous decoder, which facilitates the distillation of light detectors using high-precision large DETR models.")],-1),O=s("h2",{id:"summary",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#summary","aria-hidden":"true"},"#"),e(" Summary")],-1),S=s("p",null,"现存实时检测器（CNN-based）需要 NMS 进行后处理，通常难以优化且不够健壮，导致检测器的推理速度延迟；DETR 计算成本高，限制了实际运用。所以作者提出 RT-DETR，其由三部分组成：主干网络、高效混合编码器和拥有辅助预测头的 transformer 解码器。为了避免 NMS 造成的延迟，作者设计了一个实时端到端检测器，其中包括两个关键的改进组件：可以高效处理多尺度特征的混合编码器和改进对象查询初始化的 IoU 感知查询选择。与其他实时探测器和类似尺寸的端到端探测器相比，RT-DETR 在速度和精度方面都实现了最先进的性能。提出的检测器支持通过使用不同的解码器层灵活调整推理速度，而无需重新训练，这有利于实时目标检测器的实际应用。",-1);function E(F,L){const t=n("ExternalLinkIcon");return i(),r("div",null,[s("blockquote",null,[s("p",null,[e("DOI: "),s("a",b,[e("10.48550/arXiv.2304.08069"),o(t)])])]),v,w,x,k,T,R,M,_,D,z,O,S])}const I=l(f,[["render",E],["__file","DETRs-Beat-YOLOs-on-Real-time-Object-Detection.html.vue"]]);export{I as default};
